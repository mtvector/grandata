{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94acffde-a523-4bc6-9fd7-d6c0487fbe02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 15917.66it/s]\n",
      "\u001b[32m2025-03-22 18:15:33.526\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mcrandata.chrom_io\u001b[0m:\u001b[36mimport_bigwigs\u001b[0m:\u001b[36m308\u001b[0m - \u001b[1mExtracting values from 2 bigWig files...\u001b[0m\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/codecs/vlen_utf8.py:44: UserWarning: The codec `vlen-utf8` is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  return cls(**configuration_parsed)\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/core/array.py:3947: UserWarning: The dtype `StringDType()` is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  result = await AsyncArray._create_v3(\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/codecs/vlen_utf8.py:44: UserWarning: The codec `vlen-utf8` is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  return cls(**configuration_parsed)\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/api/asynchronous.py:197: UserWarning: Consolidated metadata is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  warnings.warn(\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/codecs/vlen_utf8.py:44: UserWarning: The codec `vlen-utf8` is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  return cls(**configuration_parsed)\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/codecs/vlen_utf8.py:44: UserWarning: The codec `vlen-utf8` is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  return cls(**configuration_parsed)\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/codecs/vlen_utf8.py:44: UserWarning: The codec `vlen-utf8` is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  return cls(**configuration_parsed)\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/codecs/vlen_utf8.py:44: UserWarning: The codec `vlen-utf8` is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  return cls(**configuration_parsed)\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/core/array.py:3947: UserWarning: The dtype `StringDType()` is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  result = await AsyncArray._create_v3(\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/codecs/vlen_utf8.py:44: UserWarning: The codec `vlen-utf8` is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  return cls(**configuration_parsed)\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/codecs/vlen_utf8.py:44: UserWarning: The codec `vlen-utf8` is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  return cls(**configuration_parsed)\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/codecs/vlen_utf8.py:44: UserWarning: The codec `vlen-utf8` is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  return cls(**configuration_parsed)\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/codecs/vlen_utf8.py:44: UserWarning: The codec `vlen-utf8` is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  return cls(**configuration_parsed)\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/api/asynchronous.py:197: UserWarning: Consolidated metadata is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  warnings.warn(\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/codecs/vlen_utf8.py:44: UserWarning: The codec `vlen-utf8` is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  return cls(**configuration_parsed)\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/codecs/vlen_utf8.py:44: UserWarning: The codec `vlen-utf8` is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  return cls(**configuration_parsed)\n",
      "100%|██████████| 2/2 [00:00<00:00, 89.15it/s]\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/codecs/vlen_utf8.py:44: UserWarning: The codec `vlen-utf8` is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  return cls(**configuration_parsed)\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/codecs/vlen_utf8.py:44: UserWarning: The codec `vlen-utf8` is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  return cls(**configuration_parsed)\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/core/group.py:2821: UserWarning: Object at obs-_-file_path is not recognized as a component of a Zarr hierarchy.\n",
      "  warnings.warn(\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/core/group.py:2821: UserWarning: Object at var-_-chrom is not recognized as a component of a Zarr hierarchy.\n",
      "  warnings.warn(\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/core/group.py:2821: UserWarning: Object at var-_-chunk_index is not recognized as a component of a Zarr hierarchy.\n",
      "  warnings.warn(\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/core/group.py:2821: UserWarning: Object at var-_-start is not recognized as a component of a Zarr hierarchy.\n",
      "  warnings.warn(\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/core/group.py:2821: UserWarning: Object at obs-_-index is not recognized as a component of a Zarr hierarchy.\n",
      "  warnings.warn(\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/core/group.py:2821: UserWarning: Object at var-_-index is not recognized as a component of a Zarr hierarchy.\n",
      "  warnings.warn(\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/core/group.py:2821: UserWarning: Object at seq_bins is not recognized as a component of a Zarr hierarchy.\n",
      "  warnings.warn(\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/core/group.py:2821: UserWarning: Object at obs is not recognized as a component of a Zarr hierarchy.\n",
      "  warnings.warn(\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/core/group.py:2821: UserWarning: Object at var is not recognized as a component of a Zarr hierarchy.\n",
      "  warnings.warn(\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/core/group.py:2821: UserWarning: Object at var-_-end is not recognized as a component of a Zarr hierarchy.\n",
      "  warnings.warn(\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/core/group.py:2821: UserWarning: Object at X is not recognized as a component of a Zarr hierarchy.\n",
      "  warnings.warn(\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/codecs/vlen_utf8.py:44: UserWarning: The codec `vlen-utf8` is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  return cls(**configuration_parsed)\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/core/array.py:3947: UserWarning: The dtype `StringDType()` is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  result = await AsyncArray._create_v3(\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/codecs/vlen_utf8.py:44: UserWarning: The codec `vlen-utf8` is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  return cls(**configuration_parsed)\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/core/array.py:3947: UserWarning: The dtype `StringDType()` is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  result = await AsyncArray._create_v3(\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/codecs/vlen_utf8.py:44: UserWarning: The codec `vlen-utf8` is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  return cls(**configuration_parsed)\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/codecs/vlen_utf8.py:44: UserWarning: The codec `vlen-utf8` is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  return cls(**configuration_parsed)\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/codecs/vlen_utf8.py:44: UserWarning: The codec `vlen-utf8` is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  return cls(**configuration_parsed)\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/api/asynchronous.py:197: UserWarning: Consolidated metadata is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  warnings.warn(\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/codecs/vlen_utf8.py:44: UserWarning: The codec `vlen-utf8` is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  return cls(**configuration_parsed)\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/codecs/vlen_utf8.py:44: UserWarning: The codec `vlen-utf8` is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  return cls(**configuration_parsed)\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/codecs/vlen_utf8.py:44: UserWarning: The codec `vlen-utf8` is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  return cls(**configuration_parsed)\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/codecs/vlen_utf8.py:44: UserWarning: The codec `vlen-utf8` is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  return cls(**configuration_parsed)\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/codecs/vlen_utf8.py:44: UserWarning: The codec `vlen-utf8` is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  return cls(**configuration_parsed)\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/codecs/vlen_utf8.py:44: UserWarning: The codec `vlen-utf8` is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  return cls(**configuration_parsed)\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/core/array.py:3947: UserWarning: The dtype `StringDType()` is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  result = await AsyncArray._create_v3(\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/codecs/vlen_utf8.py:44: UserWarning: The codec `vlen-utf8` is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  return cls(**configuration_parsed)\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/codecs/vlen_utf8.py:44: UserWarning: The codec `vlen-utf8` is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  return cls(**configuration_parsed)\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/codecs/vlen_utf8.py:44: UserWarning: The codec `vlen-utf8` is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  return cls(**configuration_parsed)\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/codecs/vlen_utf8.py:44: UserWarning: The codec `vlen-utf8` is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  return cls(**configuration_parsed)\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/api/asynchronous.py:197: UserWarning: Consolidated metadata is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  warnings.warn(\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/codecs/vlen_utf8.py:44: UserWarning: The codec `vlen-utf8` is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  return cls(**configuration_parsed)\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/codecs/vlen_utf8.py:44: UserWarning: The codec `vlen-utf8` is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  return cls(**configuration_parsed)\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/codecs/vlen_utf8.py:44: UserWarning: The codec `vlen-utf8` is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  return cls(**configuration_parsed)\n",
      "/allen/programs/celltypes/workgroups/rnaseqanalysis/EvoGen/Team/Matthew/code/grandada/crandata/_module.py:154: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  dim_dict = dict(self.adata.dims)\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/codecs/vlen_utf8.py:44: UserWarning: The codec `vlen-utf8` is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  return cls(**configuration_parsed)\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/codecs/vlen_utf8.py:44: UserWarning: The codec `vlen-utf8` is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  return cls(**configuration_parsed)\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/codecs/vlen_utf8.py:44: UserWarning: The codec `vlen-utf8` is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  return cls(**configuration_parsed)\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/xbatcher/generators.py:112: UserWarning: The following dimensions were included in both ``input_dims`` and ``batch_dims``. Since ``concat_input_dims`` is ``False``, these dimensions will not impact batch generation: {'var': 3}\n",
      "  warnings.warn(\n",
      "/allen/programs/celltypes/workgroups/rnaseqanalysis/EvoGen/Team/Matthew/code/grandada/crandata/_module.py:154: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  dim_dict = dict(self.adata.dims)\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/codecs/vlen_utf8.py:44: UserWarning: The codec `vlen-utf8` is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  return cls(**configuration_parsed)\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/codecs/vlen_utf8.py:44: UserWarning: The codec `vlen-utf8` is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  return cls(**configuration_parsed)\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/zarr/codecs/vlen_utf8.py:44: UserWarning: The codec `vlen-utf8` is currently not part in the Zarr format 3 specification. It may not be supported by other zarr implementations and may change in the future.\n",
      "  return cls(**configuration_parsed)\n",
      "/home/matthew.schmitz/Matthew/utils/miniforge3/envs/crested/lib/python3.12/site-packages/xbatcher/generators.py:112: UserWarning: The following dimensions were included in both ``input_dims`` and ``batch_dims``. Since ``concat_input_dims`` is ``False``, these dimensions will not impact batch generation: {'var': 3}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded CrAnData:\n",
      "CrAnData object\n",
      "Array names: ['var-_-chunk_index', 'obs-_-file_path', 'var-_-chrom', 'obs-_-index', 'X', 'var-_-index', 'var-_-end', 'var-_-start', 'sequences', 'var-_-split']\n",
      "Coordinates: ['var', 'obs', 'seq_bins']\n",
      "\n",
      "<xarray.DataArray 'var-_-split' (var: 3)> Size: 3B\n",
      "array([ True,  True,  True])\n",
      "Coordinates:\n",
      "  * var      (var) object 24B 'chr1:100-200' 'chr1:300-400' 'chr1:350-450'\n",
      "<xarray.DataArray 'var-_-split' (var: 3)> Size: 3B\n",
      "array([ True,  True,  True])\n",
      "Coordinates:\n",
      "  * var      (var) object 24B 'chr1:100-200' 'chr1:300-400' 'chr1:350-450'\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'RoundRobinNode' object has no attribute '_generators'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 128\u001b[0m\n\u001b[1;32m    125\u001b[0m     mod\u001b[38;5;241m.\u001b[39msetup(state\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# Retrieve the training dataloader from the meta module and iterate over a couple of batches.\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m meta_train_dl \u001b[38;5;241m=\u001b[39m \u001b[43mmeta_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIterating over a couple of training batches from MetaCrAnDataModule:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm\u001b[38;5;241m.\u001b[39mtqdm(meta_train_dl)):\n",
      "File \u001b[0;32m/allen/programs/celltypes/workgroups/rnaseqanalysis/EvoGen/Team/Matthew/code/grandada/crandata/_module.py:256\u001b[0m, in \u001b[0;36mMetaCrAnDataModule.train_dataloader\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m nodes \u001b[38;5;241m=\u001b[39m [IterableWrapper(mod) \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodules]\n\u001b[1;32m    253\u001b[0m multi_node \u001b[38;5;241m=\u001b[39m RoundRobinNode(\n\u001b[1;32m    254\u001b[0m     nodes, concat_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_dim, join\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjoin, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_workers\n\u001b[1;32m    255\u001b[0m )\n\u001b[0;32m--> 256\u001b[0m multi_node \u001b[38;5;241m=\u001b[39m \u001b[43mCrAnDataNode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmulti_node\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Loader(multi_node)\n",
      "File \u001b[0;32m/allen/programs/celltypes/workgroups/rnaseqanalysis/EvoGen/Team/Matthew/code/grandada/crandata/_module.py:36\u001b[0m, in \u001b[0;36mCrAnDataNode.__init__\u001b[0;34m(self, module, state)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule \u001b[38;5;241m=\u001b[39m module\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m state\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generators\u001b[49m:\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerator for state \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not set. Call setup(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m) first.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule\u001b[38;5;241m.\u001b[39m_generators[state]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RoundRobinNode' object has no attribute '_generators'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyBigWig\n",
    "import copy\n",
    "import xarray as xr\n",
    "import tqdm\n",
    "\n",
    "# Import our new module system and utilities.\n",
    "import crandata\n",
    "from crandata import CrAnDataModule, MetaCrAnDataModule, CrAnData\n",
    "from crandata.chrom_io import import_bigwigs\n",
    "from crandata.seq_io import add_genome_sequences_to_crandata, DNATransform\n",
    "\n",
    "# Create temporary directories for synthetic data.\n",
    "temp_dir = tempfile.TemporaryDirectory()\n",
    "base_dir = Path(temp_dir.name)\n",
    "beds_dir = base_dir / \"beds\"\n",
    "bigwigs_dir = base_dir / \"bigwigs\"\n",
    "beds_dir.mkdir(exist_ok=True)\n",
    "bigwigs_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Create a chromsizes file.\n",
    "chromsizes_file = base_dir / \"chrom.sizes\"\n",
    "with open(chromsizes_file, \"w\") as f:\n",
    "    f.write(\"chr1\\t1000\\n\")\n",
    "\n",
    "# Create two BED files (simulate two different classes).\n",
    "bed_data_A = pd.DataFrame({\n",
    "    0: [\"chr1\", \"chr1\"],\n",
    "    1: [100, 300],\n",
    "    2: [200, 400]\n",
    "})\n",
    "bed_data_B = pd.DataFrame({\n",
    "    0: [\"chr1\", \"chr1\"],\n",
    "    1: [150, 350],\n",
    "    2: [250, 450]\n",
    "})\n",
    "bed_file_A = beds_dir / \"ClassA.bed\"\n",
    "bed_file_B = beds_dir / \"ClassB.bed\"\n",
    "bed_data_A.to_csv(bed_file_A, sep=\"\\t\", header=False, index=False)\n",
    "bed_data_B.to_csv(bed_file_B, sep=\"\\t\", header=False, index=False)\n",
    "\n",
    "# Create a consensus BED file.\n",
    "consensus = pd.DataFrame({\n",
    "    0: [\"chr1\", \"chr1\", \"chr1\"],\n",
    "    1: [100, 300, 350],\n",
    "    2: [200, 400, 450]\n",
    "})\n",
    "consensus_file = base_dir / \"consensus.bed\"\n",
    "consensus.to_csv(consensus_file, sep=\"\\t\", header=False, index=False)\n",
    "\n",
    "# Create two bigWig files.\n",
    "bigwig_file1 = bigwigs_dir / \"test.bw\"\n",
    "bw1 = pyBigWig.open(str(bigwig_file1), \"w\")\n",
    "bw1.addHeader([(\"chr1\", 1000)])\n",
    "bw1.addEntries(chroms=[\"chr1\"], starts=[0], ends=[1000], values=[5.0])\n",
    "bw1.close()\n",
    "\n",
    "bigwig_file2 = bigwigs_dir / \"test2.bw\"\n",
    "bw2 = pyBigWig.open(str(bigwig_file2), \"w\")\n",
    "bw2.addHeader([(\"chr1\", 1000)])\n",
    "bw2.addEntries(chroms=[\"chr1\"], starts=[0], ends=[1000], values=[4.0])\n",
    "bw2.close()\n",
    "\n",
    "# Set extraction parameters.\n",
    "target_region_width = 100\n",
    "backed_path = base_dir / \"chrom_data.zarr\"\n",
    "\n",
    "# Create the CrAnData object from bigWig files and consensus regions.\n",
    "adata = import_bigwigs(\n",
    "    bigwigs_folder=str(bigwigs_dir),\n",
    "    regions_file=str(consensus_file),\n",
    "    backed_path=str(backed_path),\n",
    "    target_region_width=target_region_width,\n",
    "    chromsizes_file=str(chromsizes_file),\n",
    ")\n",
    "\n",
    "crandata.train_val_test_split(adata,strategy='chr_auto')\n",
    "\n",
    "# Create a dummy FASTA file for a genome.\n",
    "fasta_file = base_dir / \"chr1.fa\"\n",
    "with open(fasta_file, \"w\") as f:\n",
    "    f.write(\">chr1\\n\")\n",
    "    f.write(\"A\" * 1000 + \"\\n\")\n",
    "\n",
    "# Create a Genome object.\n",
    "from crandata._genome import Genome\n",
    "dummy_genome = Genome(str(fasta_file), chrom_sizes=str(chromsizes_file))\n",
    "\n",
    "# Add sequences to the CrAnData using the provided seq_io utility.\n",
    "# Here we use the consensus regions as our ranges.\n",
    "consensus.columns = ['chrom', 'start', 'end']\n",
    "adata = add_genome_sequences_to_crandata(adata, consensus, dummy_genome)\n",
    "\n",
    "# Write the CrAnData object to disk and then reload it to ensure sequences are out-of-memory.\n",
    "adata.to_zarr(str(backed_path),mode='a')\n",
    "adata_loaded = CrAnData.open_zarr(str(backed_path))\n",
    "print(\"Loaded CrAnData:\")\n",
    "print(adata_loaded)\n",
    "\n",
    "# Create two copies to simulate two datasets (e.g. two species), and add a \"split\" column in var metadata.\n",
    "adata1 = copy.deepcopy(adata_loaded)\n",
    "adata2 = copy.deepcopy(adata_loaded)\n",
    "adata1[\"var-_-split\"] = xr.DataArray(np.full(adata1.sizes[\"var\"], \"train\"), dims=[\"var\"])\n",
    "adata2[\"var-_-split\"] = xr.DataArray(np.full(adata2.sizes[\"var\"], \"train\"), dims=[\"var\"])\n",
    "\n",
    "# Create a DNATransform instance.\n",
    "transform = DNATransform(out_len=80, random_rc=True, max_shift=5)\n",
    "\n",
    "# Instantiate the MetaCrAnDataModule with the two datasets.\n",
    "# Note: The batch_size is now 3, matching the number of consensus regions (var dimension).\n",
    "meta_module = MetaCrAnDataModule(\n",
    "    adatas=[adata1, adata2],\n",
    "    batch_size=3,        # adjust batch size to not exceed var length (3)\n",
    "    shuffle=True,\n",
    "    dnatransform=transform,\n",
    "    epoch_size=10\n",
    ")\n",
    "\n",
    "# Setup each underlying module for the \"train\" stage.\n",
    "for mod in meta_module.modules:\n",
    "    mod.setup(state=\"train\")\n",
    "\n",
    "# Retrieve the training dataloader from the meta module and iterate over a couple of batches.\n",
    "meta_train_dl = meta_module.train_dataloader\n",
    "print(\"\\nIterating over a couple of training batches from MetaCrAnDataModule:\")\n",
    "for i, batch in enumerate(tqdm.tqdm(meta_train_dl)):\n",
    "    print(batch)\n",
    "    print(f\"\\nMeta Batch {i}:\")\n",
    "    for key, tensor in batch.items():\n",
    "        print(f\"  {key}: shape {tensor.shape}\")\n",
    "    if i >= 1:\n",
    "        break\n",
    "\n",
    "print(\"\\nTemporary directory contents:\")\n",
    "print(os.listdir(base_dir))\n",
    "temp_dir.cleanup()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97226999-8fcd-42c1-85cd-bb92946527ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ecf98f-a2c7-4d9d-8d57-5473514db1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata['var-_-split'] = xr.DataArray(pd.Series([1,2,3]).to_numpy(),dims=['var'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b68a82-cf49-4a8d-82af-b83231db3a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata['var-_-split']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d90ed71-5efb-4534-b2e9-4bee75805488",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cb0a57-e333-4776-9786-e3eeaf1ba370",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac6455b-1f4e-4b65-8ea8-e15602c43ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should the fill in _extract_values_from_bigwig actually be 0? Can we filter var where all is 0/nan without loading everything into memory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f70292f-f088-4e9d-a127-4736bb591964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import crandata\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import crested\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b454e2de-689f-432e-9621-4d88f73e3b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "genomes = {}\n",
    "beds = {}\n",
    "chromsizes_files = {}\n",
    "bed_files = {}\n",
    "species = ['mouse','human','macaque']\n",
    "\n",
    "WINDOW_SIZE = 2114\n",
    "OFFSET = WINDOW_SIZE // 2  # e.g., 50% overlap\n",
    "N_THRESHOLD = 0.3\n",
    "n_bins = WINDOW_SIZE//50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392bdeca-411d-47ea-a846-6c906784b46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in species:\n",
    "    genome_path = '/allen/programs/celltypes/workgroups/rnaseqanalysis/EvoGen/Team/Matthew/genome/onehots/'+s\n",
    "    fasta_file = os.path.join(genome_path,s+'.fa')\n",
    "    chrom_sizes = os.path.join(genome_path,s+'.fa.sizes')\n",
    "    annotation_gtf_file = os.path.join(genome_path,s+'.annotation.gtf')\n",
    "    chromsizes_files[s] = chrom_sizes\n",
    "    genome = crandata.Genome(fasta_file, chrom_sizes, annotation_gtf_file)\n",
    "    genomes[s] = genome\n",
    "    # Set parameters for binning.\n",
    "    \n",
    "    # Optionally specify an output path for the BED file.\n",
    "    OUTPUT_BED = os.path.join(genome_path, \"binned_genome.bed\")\n",
    "    bed_files[s] = OUTPUT_BED\n",
    "    # Generate bins and optionally write to disk.\n",
    "    binned_df = crandata.bin_genome(genome, WINDOW_SIZE, OFFSET, n_threshold=N_THRESHOLD, output_path=OUTPUT_BED).reset_index(drop=True)\n",
    "    print(\"Filtered bins:\")\n",
    "    print(binned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a7ce09-e4f1-4c16-bdc3-e8f390dde2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "crandata.chrom_io = importlib.reload(crandata.chrom_io)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10492d8e-e22d-48a3-8139-6d5aadc02d7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adatas = {}\n",
    "\n",
    "for s in species:\n",
    "    bigwigs_dir = os.path.join('/allen/programs/celltypes/workgroups/rnaseqanalysis/EvoGen/SpinalCord/manuscript/ATAC',s,'Group_bigwig')\n",
    "    # adata = crandata.chrom_io.import_bigwigs(\n",
    "    #     bigwigs_folder=bigwigs_dir,\n",
    "    #     regions_file=bed_files[s],\n",
    "    #     backed_path='/home/matthew.schmitz/Matthew/'+s+'_spc_test.zarr',\n",
    "    #     target_region_width=WINDOW_SIZE,\n",
    "    #     chromsizes_file=chromsizes_files[s],\n",
    "    #     target = 'raw',\n",
    "    #     n_bins=n_bins\n",
    "    # )\n",
    "    # adatas[s] = adata\n",
    "    adatas[s] = crandata.crandata.CrAnData.open_zarr('/home/matthew.schmitz/Matthew/'+s+'_spc_test.zarr')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cd7c04-0d92-4300-b098-e3f0431b7071",
   "metadata": {},
   "outputs": [],
   "source": [
    "adatas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fa88d3-f313-466e-858e-9e8a20af3b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# adatas['mouse'].uns['chunk_size'] = 512\n",
    "# adatas['human'].uns['chunk_size'] = 512\n",
    "# adatas['macaque'].uns['chunk_size'] = 512\n",
    "# adatas['mouse'].var[\"chunk_index\"] = np.arange(adatas['mouse'].var.shape[0]) // 512\n",
    "# adatas['human'].var[\"chunk_index\"] = np.arange(adatas['human'].var.shape[0]) // 512\n",
    "# adatas['macaque'].var[\"chunk_index\"] = np.arange(adatas['macaque'].var.shape[0]) // 512\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b667671b-3508-4daf-a706-92651c186854",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in adatas.keys():\n",
    "    crested.pp.train_val_test_split(\n",
    "        adatas[s], strategy=\"region\", val_size=0.1, test_size=0.1, random_state=42\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9aaf99e-b31e-4f93-a15d-e6ca8aa65780",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_module = crandata.MetaCrAnDataModule(\n",
    "    adatas=list(adatas.values()),\n",
    "    # genomes=list(genomes.values()),\n",
    "    data_sources={'y': 'X'},\n",
    "    in_memory=False,\n",
    "    random_reverse_complement=True,\n",
    "    max_stochastic_shift=10,\n",
    "    shuffle_obs=False, obs_alignment = 'intersect',\n",
    "    shuffle=True,\n",
    "    batch_size=32,    # small batch size for testing\n",
    "    epoch_size=1000000    # small epoch size for quick testing\n",
    ")\n",
    "\n",
    "# Setup the meta module for the \"fit\" stage (train/val)\n",
    "meta_module.setup(\"fit\")\n",
    "\n",
    "# Retrieve the training dataloader from the meta module and iterate over a couple of batches.\n",
    "meta_train_dl = meta_module.train_dataloader\n",
    "\n",
    "print(\"\\nIterating over a couple of training batches from MetaAnnDataModule:\")\n",
    "for i, batch in enumerate(tqdm(meta_train_dl.data)):\n",
    "    print(f\"Meta Batch {i}:\")\n",
    "    for key, tensor in batch.items():\n",
    "        print(f\"  {key}: shape {tensor.shape}\")\n",
    "    if i == 5:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0402bad-e439-4bc3-807e-0002e340138d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52795a1-dccf-4a75-a9c8-e5ee4b416051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import xbatcher\n",
    "\n",
    "# Create an xarray Dataset with 5 variables of various shapes and dimensions\n",
    "ds = xr.Dataset({\n",
    "    'var1': (('time', 'lat', 'lon'), np.random.rand(20, 10, 15)),      # e.g. climate data\n",
    "    'var2': (('time', 'lat', 'lon'), np.random.rand(20, 10, 15)),                        # e.g. 2D image-like array\n",
    "    'var3': (('time', 'lat'), np.random.rand(20, 10)),\n",
    "    },\n",
    "    coords = {'time':list(range(20)),'lat':list(range(10)),'lon':list(range(15))}\n",
    ")\n",
    "\n",
    "bgen1 = xbatcher.BatchGenerator(ds=ds[['var1','var2','var3']], input_dims=dict(ds.dims))\n",
    "print(f'bgen1 has {len(bgen1)} batches')\n",
    "print(\"First batch from var1:\")\n",
    "print(bgen1[0])\n",
    "\n",
    "ds2 = xr.Dataset({\n",
    "    'var1': (('time', 'lat', 'lon'), np.random.rand(20, 8, 15)),      # e.g. climate data\n",
    "    'var2': (('time', 'lat', 'lon'), np.random.rand(20, 8, 15)),                        # e.g. 2D image-like array\n",
    "    'var3': (('time', 'lat'), np.random.rand(20, 8)), \n",
    "    },\n",
    "    coords = {'time':list(range(20)),'lat':list(range(8)),'lon':list(range(15))}\n",
    ")\n",
    "bgen2 = xbatcher.BatchGenerator(ds=ds2[['var1','var2','var3']], input_dims=dict(ds2.dims))\n",
    "print(f'bgen2 has {len(bgen2)} batches')\n",
    "print(\"First batch from var1:\")\n",
    "print(bgen2[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14f9fdf-0d9b-4e32-8537-72207a0e0556",
   "metadata": {},
   "outputs": [],
   "source": [
    " xr.concat([bgen1[0],bgen2[0]],dim='time',join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd0c1b0-418e-4f9a-bcf4-8825ffc23651",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchdata.nodes import Mapper, MultiNodeWeightedSampler, IterableWrapper, Loader, BaseNode,ParallelMapper\n",
    "import collections\n",
    "concat_axis = 'time'\n",
    "join_param = 'inner'\n",
    "def combine_samples(x):\n",
    "    return xr.concat([next(i) for i in x],dim=concat_axis,join=join_param)\n",
    "\n",
    "datasets = IterableWrapper([bgen1, bgen2])\n",
    "\n",
    "multi_node_sampler = ParallelMapper(datasets, map_fn=combine_samples, num_workers=3, method=\"thread\")\n",
    "\n",
    "# Since nodes are iterators, they need to be manually .reset() between epochs.\n",
    "# We can wrap the root node in Loader to convert it to a more conventional Iterable.\n",
    "loader = Loader(multi_node_sampler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b863ea-0fbc-4671-9ac2-5626718b6493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import xbatcher\n",
    "from torchdata.nodes import BaseNode, IterableWrapper, Loader, ParallelMapper\n",
    "\n",
    "def combine_round_robin(*batches, concat_dim='time', join='inner'):\n",
    "    # Concatenate batches from each generator along the given dimension.\n",
    "    return xr.concat(batches, dim=concat_dim, join=join)\n",
    "\n",
    "class RoundRobinNode(BaseNode):\n",
    "    def __init__(self, nodes, combine_fn, concat_dim='time', join='inner'):\n",
    "        super().__init__()\n",
    "        self.nodes = nodes\n",
    "        self.combine_fn = combine_fn\n",
    "        self.concat_dim = concat_dim\n",
    "        self.join = join\n",
    "\n",
    "    def reset(self, initial_state=None):\n",
    "        super().reset(initial_state)\n",
    "        for node in self.nodes:\n",
    "            node.reset(initial_state)\n",
    "\n",
    "    def get_state(self):\n",
    "        return {i: node.get_state() for i, node in enumerate(self.nodes)}\n",
    "\n",
    "    def _get_next_batch(self, node):\n",
    "        # Attempt to fetch the next batch; if exhausted, reset and try again.\n",
    "        try:\n",
    "            return next(node)\n",
    "        except StopIteration:\n",
    "            node.reset()\n",
    "            return next(node)\n",
    "\n",
    "    def next(self):\n",
    "        # Use ParallelMapper to apply _get_next_batch to each node concurrently.\n",
    "        mapper = ParallelMapper(\n",
    "            source=IterableWrapper(self.nodes),\n",
    "            map_fn=self._get_next_batch,\n",
    "            num_workers=1,\n",
    "            method=\"thread\"\n",
    "        )\n",
    "        batches = list(mapper)\n",
    "        return self.combine_fn(*batches, concat_dim=self.concat_dim, join=self.join)\n",
    "\n",
    "# Example usage:\n",
    "# Assume bgen1 and bgen2 are your xbatcher BatchGenerators.\n",
    "node1 = IterableWrapper(bgen1)\n",
    "node2 = IterableWrapper(bgen2)\n",
    "\n",
    "# Create the round-robin node to concurrently retrieve a batch from each generator.\n",
    "round_robin_node = RoundRobinNode(\n",
    "    [node1, node2],\n",
    "    combine_round_robin,\n",
    "    concat_dim='time',\n",
    "    join='inner'\n",
    ")\n",
    "\n",
    "# Wrap it in a Loader for a dataloader-like interface.\n",
    "loader = Loader(round_robin_node)\n",
    "print('made loader')\n",
    "# Iterate over the loader to obtain mixed batches.\n",
    "for mixed_batch in loader:\n",
    "    print(mixed_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60a0c1e-d7c8-49f9-b1df-4b413b96e8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import xbatcher\n",
    "from torchdata.nodes import BaseNode, IterableWrapper, Loader\n",
    "\n",
    "# Custom node that sequentially yields batches from a list of nodes.\n",
    "class SequentialNode(BaseNode):\n",
    "    def __init__(self, nodes):\n",
    "        super().__init__()\n",
    "        self.nodes = nodes\n",
    "        self.current = 0\n",
    "\n",
    "    def reset(self, initial_state=None):\n",
    "        super().reset(initial_state)\n",
    "        for node in self.nodes:\n",
    "            node.reset(initial_state)\n",
    "        self.current = 0\n",
    "\n",
    "    def get_state(self):\n",
    "        return {\n",
    "            \"current\": self.current,\n",
    "            \"states\": [node.get_state() for node in self.nodes]\n",
    "        }\n",
    "\n",
    "    def next(self):\n",
    "        # Loop until we find a node with data or we run out of nodes.\n",
    "        while self.current < len(self.nodes):\n",
    "            try:\n",
    "                # Attempt to fetch the next batch from the current node.\n",
    "                return next(self.nodes[self.current])\n",
    "            except StopIteration:\n",
    "                # If exhausted, move to the next node.\n",
    "                self.current += 1\n",
    "        # If all nodes are exhausted, signal end-of-iteration.\n",
    "        raise StopIteration\n",
    "\n",
    "# Example: Create two xbatcher BatchGenerators over different datasets.\n",
    "ds1 = xr.Dataset({\n",
    "    'var1': (('time', 'lat', 'lon'), xr.DataArray(100+np.random.rand(20, 10, 15)).data)\n",
    "})\n",
    "ds2 = xr.Dataset({\n",
    "    'var1': (('time', 'lat', 'lon'), xr.DataArray(np.random.rand(14, 10, 15)).data)\n",
    "})\n",
    "\n",
    "# Create BatchGenerators for each dataset.\n",
    "bgen1 = xbatcher.BatchGenerator(ds=ds1, input_dims={'time': 5, 'lat': 10, 'lon': 15})\n",
    "bgen2 = xbatcher.BatchGenerator(ds=ds2, input_dims={'time': 5, 'lat': 10, 'lon': 15})\n",
    "\n",
    "# Wrap each BatchGenerator in an IterableWrapper to convert them to torchdata nodes.\n",
    "node1 = IterableWrapper(bgen1)\n",
    "node2 = IterableWrapper(bgen2)\n",
    "\n",
    "# Create a SequentialNode that will iterate through node1 then node2.\n",
    "seq_node = SequentialNode([node1, node2])\n",
    "\n",
    "# Wrap the custom sequential node in a Loader for dataloader-like iteration.\n",
    "loader = Loader(seq_node)\n",
    "\n",
    "# Iterate over the loader to retrieve batches sequentially.\n",
    "for batch in loader:\n",
    "    print(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4519d5-00fb-4c78-8e10-1e12d6a45b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c24536-ed51-4016-bbeb-f334bf945d81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in loader:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de99d0b3-99e8-4a30-8cf4-b762a1247d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch in enumerate(tqdm(meta_train_dl.data)):\n",
    "    print(f\"Meta Batch {i}:\")\n",
    "    for key, tensor in batch.items():\n",
    "        print(f\"  {key}: shape {tensor.dtype}\")\n",
    "    if i == 5:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a11e2cb-b92b-4c02-bc40-886f67d2e8d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cProfile\n",
    "\n",
    "code = '''\n",
    "for i, batch in enumerate(meta_train_dl.data):\n",
    "    # print(f\"Meta Batch {i}:\")\n",
    "    # for key, tensor in batch.items():\n",
    "    #     print(f\"  {key}: shape {tensor.shape}\")\n",
    "    if i == 5:\n",
    "        break\n",
    "'''\n",
    "\n",
    "out = cProfile.run(code,sort=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e661681c-6d1e-4441-9878-c21d0505df51",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_architecture = crested.tl.zoo.simple_convnet(\n",
    "    seq_len=2114, num_classes=batch['y'].shape[1]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6348c92d-cfce-4e39-8a7f-3df53b363b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "# Create your own configuration\n",
    "# I recommend trying this for peak regression with a weighted cosine mse log loss function\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-5)\n",
    "loss = crested.tl.losses.CosineMSELogLoss(max_weight=100, multiplier=1)\n",
    "loss = crested.tl.losses.PoissonLoss()\n",
    "\n",
    "metrics = [\n",
    "    keras.metrics.MeanAbsoluteError(),\n",
    "    # keras.metrics.MeanSquaredError(),\n",
    "    # keras.metrics.CosineSimilarity(axis=1),\n",
    "    crested.tl.metrics.PearsonCorrelation(),\n",
    "    # crested.tl.metrics.ConcordanceCorrelationCoefficient(),\n",
    "    # crested.tl.metrics.PearsonCorrelationLog(),\n",
    "    # crested.tl.metrics.ZeroPenaltyMetric(),\n",
    "]\n",
    "\n",
    "alternative_config = crested.tl.TaskConfig(optimizer, loss, metrics)\n",
    "print(alternative_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e5aeb3-5514-466c-b8c7-f04556666c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize some lazy model parameters *yawn*\n",
    "model_architecture(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b3716a-4a11-418e-9aad-6778019c0f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = crested.tl.Crested(\n",
    "    data=meta_module,\n",
    "    model=model_architecture,\n",
    "    config=alternative_config,\n",
    "    project_name=\"mouse_biccn\",  # change to your liking\n",
    "    run_name=\"basemodel\",  # change to your liking\n",
    "    logger=None,  # or None, 'dvc', 'tensorboard'\n",
    "    seed=7,  # For reproducibility\n",
    ")\n",
    "# train the model\n",
    "trainer.fit(\n",
    "    epochs=60,\n",
    "    learning_rate_reduce_patience=3,\n",
    "    early_stopping_patience=6,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acd5a76-9f07-4525-8c6d-4b5f3ed12aae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crested",
   "language": "python",
   "name": "crested"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
